{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating and installing system packages...\n",
      "Updating and installing pip packages...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /home/vishnu/.local/lib/python3.10/site-packages (23.2.1)\n",
      "Requirement already satisfied: setuptools in /home/vishnu/.local/lib/python3.10/site-packages (68.2.2)\n",
      "Requirement already satisfied: wheel in /home/vishnu/.local/lib/python3.10/site-packages (0.41.2)\n",
      "Requirement already satisfied: httpx==0.23.0 in /home/vishnu/.local/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: faiss-gpu in /home/vishnu/.local/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: fairseq in /home/vishnu/.local/lib/python3.10/site-packages (0.12.2)\n",
      "Collecting ffmpeg\n",
      "  Using cached ffmpeg-1.4-py3-none-any.whl\n",
      "Requirement already satisfied: ffmpeg-python in /home/vishnu/.local/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: praat-parselmouth in /home/vishnu/.local/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: pyworld in /home/vishnu/.local/lib/python3.10/site-packages (0.3.4)\n",
      "Requirement already satisfied: numpy==1.23.5 in /home/vishnu/.local/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: numba==0.56.4 in /home/vishnu/.local/lib/python3.10/site-packages (0.56.4)\n",
      "Requirement already satisfied: librosa==0.9.2 in /home/vishnu/.local/lib/python3.10/site-packages (0.9.2)\n",
      "Requirement already satisfied: gdown in /home/vishnu/.local/lib/python3.10/site-packages (4.7.1)\n",
      "Requirement already satisfied: onnxruntime in /home/vishnu/.local/lib/python3.10/site-packages (1.16.0)\n",
      "Collecting onnxruntime\n",
      "  Obtaining dependency information for onnxruntime from https://files.pythonhosted.org/packages/e0/c1/236fe9621584f32ffd6c1eeba4005f1c2932d2e21ef901c321ae51b9219d/onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: certifi in /home/vishnu/.local/lib/python3.10/site-packages (from httpx==0.23.0) (2023.7.22)\n",
      "Requirement already satisfied: sniffio in /home/vishnu/.local/lib/python3.10/site-packages (from httpx==0.23.0) (1.3.0)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /home/vishnu/.local/lib/python3.10/site-packages (from httpx==0.23.0) (1.5.0)\n",
      "Requirement already satisfied: httpcore<0.16.0,>=0.15.0 in /home/vishnu/.local/lib/python3.10/site-packages (from httpx==0.23.0) (0.15.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/vishnu/.local/lib/python3.10/site-packages (from numba==0.56.4) (0.39.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/vishnu/.local/lib/python3.10/site-packages (from librosa==0.9.2) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/vishnu/.local/lib/python3.10/site-packages (from librosa==0.9.2) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/vishnu/.local/lib/python3.10/site-packages (from librosa==0.9.2) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/vishnu/.local/lib/python3.10/site-packages (from librosa==0.9.2) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /home/vishnu/.local/lib/python3.10/site-packages (from librosa==0.9.2) (5.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/vishnu/.local/lib/python3.10/site-packages (from librosa==0.9.2) (0.4.2)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /home/vishnu/.local/lib/python3.10/site-packages (from librosa==0.9.2) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/vishnu/.local/lib/python3.10/site-packages (from librosa==0.9.2) (1.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vishnu/.local/lib/python3.10/site-packages (from librosa==0.9.2) (23.2)\n",
      "Requirement already satisfied: bitarray in /home/vishnu/.local/lib/python3.10/site-packages (from fairseq) (2.8.2)\n",
      "Requirement already satisfied: cffi in /home/vishnu/.local/lib/python3.10/site-packages (from fairseq) (1.16.0)\n",
      "Requirement already satisfied: cython in /home/vishnu/.local/lib/python3.10/site-packages (from fairseq) (3.0.3)\n",
      "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /home/vishnu/.local/lib/python3.10/site-packages (from fairseq) (1.0.7)\n",
      "Requirement already satisfied: omegaconf<2.1 in /home/vishnu/.local/lib/python3.10/site-packages (from fairseq) (2.0.6)\n",
      "Requirement already satisfied: regex in /home/vishnu/.local/lib/python3.10/site-packages (from fairseq) (2023.10.3)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /home/vishnu/.local/lib/python3.10/site-packages (from fairseq) (2.3.1)\n",
      "Requirement already satisfied: torch in /home/vishnu/.local/lib/python3.10/site-packages (from fairseq) (2.1.0)\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /home/vishnu/.local/lib/python3.10/site-packages (from fairseq) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /home/vishnu/.local/lib/python3.10/site-packages (from fairseq) (4.65.0)\n",
      "Requirement already satisfied: future in /home/vishnu/.local/lib/python3.10/site-packages (from ffmpeg-python) (0.18.3)\n",
      "Requirement already satisfied: filelock in /home/vishnu/.local/lib/python3.10/site-packages (from gdown) (3.12.4)\n",
      "Requirement already satisfied: requests[socks] in /home/vishnu/.local/lib/python3.10/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/vishnu/.local/lib/python3.10/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: coloredlogs in /home/vishnu/.local/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/vishnu/.local/lib/python3.10/site-packages (from onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /home/vishnu/.local/lib/python3.10/site-packages (from onnxruntime) (4.24.4)\n",
      "Requirement already satisfied: sympy in /home/vishnu/.local/lib/python3.10/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in /home/vishnu/.local/lib/python3.10/site-packages (from httpcore<0.16.0,>=0.15.0->httpx==0.23.0) (0.12.0)\n",
      "Requirement already satisfied: anyio==3.* in /home/vishnu/.local/lib/python3.10/site-packages (from httpcore<0.16.0,>=0.15.0->httpx==0.23.0) (3.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/vishnu/.local/lib/python3.10/site-packages (from anyio==3.*->httpcore<0.16.0,>=0.15.0->httpx==0.23.0) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /home/vishnu/.local/lib/python3.10/site-packages (from anyio==3.*->httpcore<0.16.0,>=0.15.0->httpx==0.23.0) (1.1.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /home/vishnu/.local/lib/python3.10/site-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /usr/lib/python3/dist-packages (from omegaconf<2.1->fairseq) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in /home/vishnu/.local/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (4.8.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/vishnu/.local/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.2) (3.11.0)\n",
      "Requirement already satisfied: portalocker in /home/vishnu/.local/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (2.8.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/vishnu/.local/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n",
      "Requirement already satisfied: colorama in /home/vishnu/.local/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
      "Requirement already satisfied: lxml in /home/vishnu/.local/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (4.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/vishnu/.local/lib/python3.10/site-packages (from scikit-learn>=0.19.1->librosa==0.9.2) (3.2.0)\n",
      "Requirement already satisfied: pycparser in /home/vishnu/.local/lib/python3.10/site-packages (from cffi->fairseq) (2.21)\n",
      "Requirement already satisfied: networkx in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/vishnu/.local/lib/python3.10/site-packages (from torch->fairseq) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/vishnu/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq) (12.2.140)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vishnu/.local/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/vishnu/.local/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vishnu/.local/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vishnu/.local/lib/python3.10/site-packages (from requests[socks]->gdown) (2.0.6)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/vishnu/.local/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/vishnu/.local/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vishnu/.local/lib/python3.10/site-packages (from jinja2->torch->fairseq) (2.1.3)\n",
      "Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: ffmpeg, onnxruntime\n",
      "  Attempting uninstall: onnxruntime\n",
      "    Found existing installation: onnxruntime 1.16.0\n",
      "    Uninstalling onnxruntime-1.16.0:\n",
      "      Successfully uninstalled onnxruntime-1.16.0\n",
      "Successfully installed ffmpeg-1.4 onnxruntime-1.16.1\n",
      "Packages up to date.\n"
     ]
    }
   ],
   "source": [
    "#@title Install Dependencies\n",
    "import subprocess\n",
    "\n",
    "packages = []\n",
    "pip_packages = ['pip', 'setuptools', 'wheel', 'httpx==0.23.0', 'faiss-gpu', 'fairseq', 'ffmpeg', 'ffmpeg-python', 'praat-parselmouth', 'pyworld', 'numpy==1.23.5', 'numba==0.56.4', 'librosa==0.9.2', 'gdown', 'onnxruntime']\n",
    "print(\"Updating and installing system packages...\")\n",
    "for package in packages:\n",
    "  print(f\"Installing {package}...\")\n",
    "  subprocess.check_call(['sudo','apt-get', 'install', '-qq', '-y', package])\n",
    "\n",
    "print(\"Updating and installing pip packages...\")\n",
    "subprocess.check_call(['pip', 'install', '--upgrade'] + pip_packages)\n",
    "\n",
    "print('Packages up to date.')\n",
    "firsttry = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon\n",
      "Cloning into 'Mangio-RVC-Tweaks'...\n",
      "remote: Enumerating objects: 3098, done.\u001b[K\n",
      "remote: Total 3098 (delta 0), reused 0 (delta 0), pack-reused 3098\u001b[K\n",
      "Receiving objects: 100% (3098/3098), 13.84 MiB | 8.78 MiB/s, done.\n",
      "Resolving deltas: 100% (1935/1935), done.\n",
      "Cloning into 'torchcrepe'...\n",
      "remote: Enumerating objects: 442, done.\u001b[K\n",
      "remote: Counting objects: 100% (437/437), done.\u001b[K\n",
      "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
      "remote: Total 442 (delta 253), reused 395 (delta 229), pack-reused 5\u001b[K\n",
      "Receiving objects: 100% (442/442), 72.20 MiB | 17.77 MiB/s, done.\n",
      "Resolving deltas: 100% (253/253), done.\n"
     ]
    }
   ],
   "source": [
    "#@title Clone Repositories\n",
    "%cd hackathon\n",
    "import os\n",
    "\n",
    "# READ ME BEFORE CHANGING THINGS\n",
    "# If you're attempting to replace the imports here with Applio-RVC, it will not work due to requirement discrepancies across the entire notebook.\n",
    "# I will not be porting this notebook to Applio due to the failure of the Applio team to provide backwards compatibility with the Crepe and Mangio-Crepe f0 feature format.\n",
    "# DO NOT ASK. IT WILL NOT HAPPEN.\n",
    "\n",
    "os.chdir('content/')\n",
    "#Credit to Redoverflow on the AI Hub Discord for (indirectly) suggesting this variant of Mangio RVC to me.\n",
    "!git clone -b pr-optimization --single-branch https://github.com/alexlnkp/Mangio-RVC-Tweaks.git\n",
    "#Rename to keep backwards compatibility with old variants of Disconnected\n",
    "os.rename(\"Mangio-RVC-Tweaks\", \"Mangio-RVC-Fork\")\n",
    "!git clone https://github.com/maxrmorrison/torchcrepe.git\n",
    "!mv torchcrepe/torchcrepe Mangio-RVC-Fork/\n",
    "!rm -rf torchcrepe  # Delete the torchcrepe repository folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Mangio-RVC-Fork')\n",
    "\n",
    "now_dir = \"Mangio-RVC-Fork\"\n",
    "os.makedirs(os.path.join(now_dir, \"logs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(now_dir, \"weights\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compatible GPU detected: NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "#@title GPU Check\n",
    "import torch\n",
    "\n",
    "ngpu = torch.cuda.device_count()\n",
    "gpu_infos = []\n",
    "mem = []\n",
    "if_gpu_ok = False\n",
    "\n",
    "if torch.cuda.is_available() or ngpu != 0:\n",
    "  for i in range(ngpu):\n",
    "    gpu_name = torch.cuda.get_device_name(i)\n",
    "    if any(\n",
    "        value in gpu_name.upper()\n",
    "        for value in [\"10\", \"16\", \"20\", \"30\", \"40\", \"A2\", \"A3\", \"A4\", \"P4\", \"A50\", \"500\", \"A60\", \"70\", \"80\", \"90\", \"M4\", \"T4\", \"TITAN\"]\n",
    "    ):\n",
    "      if_gpu_ok = True\n",
    "      print(\"Compatible GPU detected: %s\" % gpu_name)\n",
    "      gpu_infos.append(\"%s\\t%s\" % (i, gpu_name))\n",
    "      mem.append(int(torch.cuda.get_device_properties(i).total_memory / 1024 / 1024 / 1024 + 0.4))\n",
    "\n",
    "if if_gpu_ok and len(gpu_infos) > 0:\n",
    "  gpu_info = \"\\n\".join(gpu_infos)\n",
    "\n",
    "else:\n",
    "  raise Exception(\"No GPU detected; training cannot continue. Please change your runtime type to a GPU.\")\n",
    "gpus = \"-\".join(i[0] for i in gpu_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m[\u001b[0m#b1aaf1 67MiB/69MiB\u001b[36m(97%)\u001b[0m CN:4 DL:\u001b[32m22MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m[0m\u001b[35m]\u001b[0m\u001b[0mm\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "b1aaf1|\u001b[1;32mOK\u001b[0m  |    19MiB/s|Mangio-RVC-Fork/pretrained/f0G32k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#062647 104MiB/104MiB\u001b[36m(99%)\u001b[0m CN:1 DL:\u001b[32m26MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\u001b[35m]\u001b[0m\u001b[0m\u001b[0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "062647|\u001b[1;32mOK\u001b[0m  |    25MiB/s|Mangio-RVC-Fork/pretrained/f0D32k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#99ec62 65MiB/69MiB\u001b[36m(94%)\u001b[0m CN:4 DL:\u001b[32m21MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m[0m\u001b[35m]\u001b[0m\u001b[0mm\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "99ec62|\u001b[1;32mOK\u001b[0m  |    19MiB/s|Mangio-RVC-Fork/pretrained/f0G40k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#daf084 104MiB/104MiB\u001b[36m(99%)\u001b[0m CN:1 DL:\u001b[32m20MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\u001b[35m]\u001b[0m\u001b[0m\u001b[0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "daf084|\u001b[1;32mOK\u001b[0m  |    20MiB/s|Mangio-RVC-Fork/pretrained/f0D40k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#6b6904 42MiB/69MiB\u001b[36m(60%)\u001b[0m CN:16 DL:\u001b[32m20MiB\u001b[0m ETA:\u001b[33m1s\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "6b6904|\u001b[1;32mOK\u001b[0m  |    23MiB/s|Mangio-RVC-Fork/pretrained/f0G48k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#86d952 102MiB/104MiB\u001b[36m(98%)\u001b[0m CN:2 DL:\u001b[32m25MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\u001b[35m]\u001b[0m\u001b[0m\u001b[0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "86d952|\u001b[1;32mOK\u001b[0m  |    21MiB/s|Mangio-RVC-Fork/pretrained/f0D48k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#a77ba8 67MiB/70MiB\u001b[36m(96%)\u001b[0m CN:4 DL:\u001b[32m22MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m[0m\u001b[35m]\u001b[0m\u001b[0m0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "a77ba8|\u001b[1;32mOK\u001b[0m  |    18MiB/s|Mangio-RVC-Fork/pretrained_v2/f0G32k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#81422a 136MiB/136MiB\u001b[36m(99%)\u001b[0m CN:1 DL:\u001b[32m27MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0mmm\u001b[35m]\u001b[0m\u001b[0m\u001b[0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "81422a|\u001b[1;32mOK\u001b[0m  |    26MiB/s|Mangio-RVC-Fork/pretrained_v2/f0D32k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#5468c7 67MiB/69MiB\u001b[36m(97%)\u001b[0m CN:2 DL:\u001b[32m21MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m[0m\u001b[35m]\u001b[0m\u001b[0m0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "5468c7|\u001b[1;32mOK\u001b[0m  |    17MiB/s|Mangio-RVC-Fork/pretrained_v2/f0G40k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#bf4a12 135MiB/136MiB\u001b[36m(99%)\u001b[0m CN:1 DL:\u001b[32m26MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0mmm\u001b[35m]\u001b[0m\u001b[0m\u001b[0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "bf4a12|\u001b[1;32mOK\u001b[0m  |    25MiB/s|Mangio-RVC-Fork/pretrained_v2/f0D40k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#1770f2 67MiB/71MiB\u001b[36m(94%)\u001b[0m CN:6 DL:\u001b[32m22MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m[0m\u001b[35m]\u001b[0m\u001b[0m0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "1770f2|\u001b[1;32mOK\u001b[0m  |    20MiB/s|Mangio-RVC-Fork/pretrained_v2/f0G48k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#c5bd80 122MiB/136MiB\u001b[36m(89%)\u001b[0m CN:16 DL:\u001b[32m30MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0mm\u001b[35m]\u001b[0m\u001b[0mm\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "c5bd80|\u001b[1;32mOK\u001b[0m  |    28MiB/s|Mangio-RVC-Fork/pretrained_v2/f0D48k.pth\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#efc1c6 180MiB/180MiB\u001b[36m(99%)\u001b[0m CN:1 DL:\u001b[32m25MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0mm0m\u001b[35m]\u001b[0m\u001b[0m\u001b[0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "efc1c6|\u001b[1;32mOK\u001b[0m  |    23MiB/s|Mangio-RVC-Fork/hubert_base.pt\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\u001b[35m[\u001b[0m#63f384 166MiB/172MiB\u001b[36m(96%)\u001b[0m CN:11 DL:\u001b[32m33MiB\u001b[0m\u001b[35m]\u001b[0m\u001b[0m0m\u001b[35m]\u001b[0m\u001b[0m[0m\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "63f384|\u001b[1;32mOK\u001b[0m  |    28MiB/s|Mangio-RVC-Fork/rmvpe.pt\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "77f6e3|\u001b[1;32mOK\u001b[0m  |   341KiB/s|Mangio-RVC-Fork/configs/32k.json\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "61bb49|\u001b[1;32mOK\u001b[0m  |   510KiB/s|Mangio-RVC-Fork/configs/40k.json\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "d71c0f|\u001b[1;32mOK\u001b[0m  |   512KiB/s|Mangio-RVC-Fork/configs/48k.json\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n"
     ]
    }
   ],
   "source": [
    "#@title Download Pretrained Models\n",
    "#Didn't ask.\n",
    "\n",
    "#V1 Models\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0G32k.pth -d Mangio-RVC-Fork/pretrained -o f0G32k.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0D32k.pth -d Mangio-RVC-Fork/pretrained -o f0D32k.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0G40k.pth -d Mangio-RVC-Fork/pretrained -o f0G40k.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0D40k.pth -d Mangio-RVC-Fork/pretrained -o f0D40k.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0G48k.pth -d Mangio-RVC-Fork/pretrained -o f0G48k.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/v1/f0D48k.pth -d Mangio-RVC-Fork/pretrained -o f0D48k.pth\n",
    "\n",
    "#V2 Models\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G32k.pth -d Mangio-RVC-Fork/pretrained_v2 -o f0G32k.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D32k.pth -d Mangio-RVC-Fork/pretrained_v2 -o f0D32k.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G40k.pth -d Mangio-RVC-Fork/pretrained_v2 -o f0G40k.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D40k.pth -d Mangio-RVC-Fork/pretrained_v2 -o f0D40k.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0G48k.pth -d Mangio-RVC-Fork/pretrained_v2 -o f0G48k.pth\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/f0D48k.pth -d Mangio-RVC-Fork/pretrained_v2 -o f0D48k.pth\n",
    "\n",
    "#RMVPE and Hubert\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/hubert_base.pt -d Mangio-RVC-Fork -o hubert_base.pt\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/rmvpe.pt -d Mangio-RVC-Fork -o rmvpe.pt\n",
    "\n",
    "#fp_16 Variant JSONs\n",
    "!rm -rf Mangio-RVC-Fork/configs/32k.json\n",
    "!rm -rf Mangio-RVC-Fork/configs/40k.json\n",
    "!rm -rf Mangio-RVC-Fork/configs/48k.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/32k.json -d Mangio-RVC-Fork/configs -o 32k.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/40k.json -d Mangio-RVC-Fork/configs -o 40k.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/48k.json -d Mangio-RVC-Fork/configs -o 48k.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup CSVDB\n",
    "#...Alright, you made your point.\n",
    "import csv\n",
    "\n",
    "if not os.path.isdir(\"csvdb/\"):\n",
    "  os.makedirs(\"csvdb\")\n",
    "  frmnt, stp = open(\"csvdb/formanting.csv\", \"w\", newline=\"\"), open(\"csvdb/stop.csv\", \"w\", newline=\"\")\n",
    "  csv_writer = csv.writer(frmnt, delimiter=\",\")\n",
    "  csv_writer.writerow([False, 1.0, 1.0])\n",
    "  csv_writer = csv.writer(stp, delimiter=\",\")\n",
    "  csv_writer.writerow([False])\n",
    "  frmnt.close()\n",
    "  stp.close()\n",
    "\n",
    "global DoFormant, Quefrency, Timbre\n",
    "DoFormant, Quefrency, Timbre = False, 1.0, 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Set Training Variables\n",
    "now_dir = \"Mangio-RVC-Fork\"\n",
    "experiment_name = \"v_voice\" #@param {type:\"string\"}\n",
    "path_to_training_folder = \"dataset/\"\n",
    "model_architecture = \"v2\" #@param [\"v1\",\"v2\"] {allow-input: false}\n",
    "target_sample_rate = \"48k\" #@param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n",
    "cpu_threads = 2 #@param {type:\"integer\"}\n",
    "speaker_id = 0 #@param {type:\"integer\"}\n",
    "pitch_extraction_algorithm = \"rmvpe\" #@param [\"harvest\", \"crepe\", \"mangio-crepe\", \"rmvpe\"] {allow-input: false}\n",
    "crepe_hop_length = 64 #@param {type:\"integer\"}\n",
    "pitch_guidance = True #@param {type:\"boolean\"}\n",
    "\n",
    "assert crepe_hop_length!=None, \"You need to input something for crepe_hop_length, silly.\"\n",
    "assert crepe_hop_length>0, \"Hop length must be more than 0.\"\n",
    "assert crepe_hop_length<=512, \"Save frequency must be less than 512.\"\n",
    "\n",
    "if(experiment_name == \"experiment_name\"):\n",
    "  print(\"Warning: Your experiment name should be changed to the name of your dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content\n"
     ]
    }
   ],
   "source": [
    "%cd hackathon/content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  drive/MyDrive/rvcDisconnected/data_vishnu.zip\n",
      "  inflating: temp_dataset/data_vishnu/file1.wav  \n",
      "  inflating: temp_dataset/data_vishnu/file2.wav  \n",
      "  inflating: temp_dataset/data_vishnu/file3.wav  \n",
      "  inflating: temp_dataset/data_vishnu/file4.wav  \n",
      "  inflating: temp_dataset/data_vishnu/file5.wav  \n",
      "  inflating: temp_dataset/data_vishnu/file6.wav  \n",
      "  inflating: temp_dataset/data_vishnu/file7.wav  \n",
      "  inflating: temp_dataset/data_vishnu/file8.wav  \n",
      "  inflating: temp_dataset/data_vishnu/file9.wav  \n",
      "Sanitizing...\n",
      "Dataset Type: Single Speaker\n",
      "Dataset imported.\n"
     ]
    }
   ],
   "source": [
    "#@title Load Dataset\n",
    "#@markdown If it doesn't already exist, create a folder in your Google Drive named 'rvcDisconnected' and place your zip file there. This will look for the following ZIP file inside that 'rvcDisconnected' folder.\n",
    "dataset = \"data_vishnu.zip\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown This loader will load datasets in a similar fashion to the So-Vits-SVC dataset loader. For best results, your dataset should be formatted as such:\n",
    "#@markdown ```\n",
    "#@markdown zipfile.zip\n",
    "#@markdown └───character_name\n",
    "#@markdown     ├───file1.wav\n",
    "#@markdown     ├───...\n",
    "#@markdown     └───file999.wav\n",
    "#@markdown ```\n",
    "#@markdown Audio filenames do not matter. All audio files should be in WAV format for best compatibility.\n",
    "\n",
    "# TODO: Add something to convert non-WAVs to WAV\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "directories=[]\n",
    "\n",
    "def sanitize_directory(directory):\n",
    "  for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "      if filename == \".DS_Store\" or filename.startswith(\"._\") or not filename.endswith(('.wav', '.flac', '.mp3', '.ogg', '.m4a')):\n",
    "        os.remove(file_path)\n",
    "    elif os.path.isdir(file_path):\n",
    "      #Get rid of the MACOSX directory just so it doesn't mess with renaming later\n",
    "      if(filename == \"__MACOSX\"):\n",
    "        shutil.rmtree(file_path)\n",
    "        continue\n",
    "      #Append the directory to directories for future dataset check, then recurse.\n",
    "      directories.append(file_path)\n",
    "      sanitize_directory(file_path)\n",
    "\n",
    "dataset_path = 'drive/MyDrive/rvcDisconnected/' + dataset\n",
    "final_directory = 'dataset'\n",
    "temp_directory = 'temp_dataset'\n",
    "\n",
    "if os.path.exists(final_directory):\n",
    "  print(\"Dataset folder already found. Wiping...\")\n",
    "  shutil.rmtree(final_directory)\n",
    "if os.path.exists(temp_directory):\n",
    "  print(\"Temporary folder already found. Wiping...\")\n",
    "  shutil.rmtree(temp_directory)\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "  raise Exception(f'I can\\'t find {dataset} in {os.path.dirname(dataset_path)}.')\n",
    "\n",
    "os.makedirs(final_directory, exist_ok=True)\n",
    "os.makedirs(temp_directory, exist_ok=True)\n",
    "#Oops.\n",
    "!unzip -d \"{temp_directory}\" -B \"{dataset_path}\"\n",
    "print(\"Sanitizing...\")\n",
    "sanitize_directory(temp_directory)\n",
    "\n",
    "if(len(directories) == 0):\n",
    "  #If there's no directories, we're dealing with a ZIP of just audio files.\n",
    "  #Move everything to /dataset/experiment_name/.\n",
    "  print(\"Dataset Type: Audio Files (Single Speaker)\")\n",
    "  expDir=os.path.join(final_directory, experiment_name)\n",
    "  os.makedirs(expDir, exist_ok=True)\n",
    "  for r, _, f in os.walk(temp_directory):\n",
    "    for name in f:\n",
    "      !cp \"{temp_directory}/{name}\" \"{expDir}\"\n",
    "elif(len(directories) == 1):\n",
    "  #If there's only one directory, we're dealing with a single speaker.\n",
    "  #Rename the folder to experiment_name and move it to /dataset/.\n",
    "  print(\"Dataset Type: Single Speaker\")\n",
    "  fi = os.path.join(temp_directory, experiment_name)\n",
    "  os.rename(directories[0], fi)\n",
    "  shutil.move(fi, final_directory)\n",
    "\n",
    "else:\n",
    "  #If anything else, we're dealing with multispeaker.\n",
    "  #Move all folders to /dataset/ indiscriminately.\n",
    "  print(\"Dataset Type: Multispeaker\")\n",
    "  for fi in directories:\n",
    "    shutil.move(fi, final_directory)\n",
    "\n",
    "shutil.rmtree(temp_directory)\n",
    "\n",
    "print(\"Dataset imported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 Mangio-RVC-Fork/trainset_preprocess_pipeline_print.py \"dataset/v_voice\" 48000 2 \"Mangio-RVC-Fork/logs/v_voice\" 1\n",
      "start preprocess\n",
      "['Mangio-RVC-Fork/trainset_preprocess_pipeline_print.py', 'dataset/v_voice', '48000', '2', 'Mangio-RVC-Fork/logs/v_voice', '1']\n",
      "thread:0:   0%|                                           | 0/5 [00:00<?, ?it/s]\n",
      "thread:1:   0%|                                           | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "thread:0:  40%|██████████████                     | 2/5 [00:01<00:01,  1.95it/s]\u001b[A\n",
      "thread:0:  60%|█████████████████████              | 3/5 [00:01<00:00,  2.57it/s]\u001b[A\n",
      "thread:0:  80%|████████████████████████████       | 4/5 [00:01<00:00,  3.35it/s]\u001b[A\n",
      "thread:1: 100%|███████████████████████████████████| 4/4 [00:01<00:00,  2.53it/s]\u001b[A\n",
      "thread:0: 100%|███████████████████████████████████| 5/5 [00:01<00:00,  2.87it/s]\n",
      "end preprocess\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@title Preprocessing\n",
    "# Change the Experiment Name and the Path to Training Folder. You shouldn't need to change anything else.\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "assert cpu_threads>0, \"CPU threads not allocated correctly.\"\n",
    "\n",
    "sr = int(target_sample_rate.rstrip('k'))*1000\n",
    "pttf = path_to_training_folder + experiment_name\n",
    "os.makedirs(\"%s/logs/%s\" % (now_dir, experiment_name), exist_ok=True)\n",
    "\n",
    "#%cd Mangio-RVC-Fork\n",
    "cmd = \"python3 Mangio-RVC-Fork/trainset_preprocess_pipeline_print.py \\\"%s\\\" %s %s \\\"%s/logs/%s\\\" 1\" % (pttf, sr, cpu_threads, now_dir, experiment_name)\n",
    "print(cmd)\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content\n"
     ]
    }
   ],
   "source": [
    "%cd Mangio-RVC-Fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content/Mangio-RVC-Fork\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 Mangio-RVC-Fork/extract_f0_print.py \"Mangio-RVC-Fork/logs/v_voice\" 2 rmvpe 64\n",
      "['Mangio-RVC-Fork/extract_f0_print.py', 'Mangio-RVC-Fork/logs/v_voice', '2', 'rmvpe', '64']\n",
      "Using f0 method: rmvpe\n",
      "thread:0, f0ing, Hop-Length:64:   0%|                    | 0/18 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "thread:1, f0ing, Hop-Length:64:   0%|                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64:   6%|▋           | 1/18 [00:03<00:57,  3.40s/it]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64:  17%|██          | 3/18 [00:03<00:14,  1.04it/s]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64:  22%|██▋         | 4/18 [00:03<00:09,  1.51it/s]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64:  28%|███▎        | 5/18 [00:03<00:06,  2.08it/s]\u001b[A\n",
      "thread:1, f0ing, Hop-Length:64:  28%|███▎        | 5/18 [00:03<00:05,  2.55it/s]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64:  44%|█████▎      | 8/18 [00:04<00:02,  4.16it/s]\u001b[A\n",
      "thread:1, f0ing, Hop-Length:64:  44%|█████▎      | 8/18 [00:04<00:02,  4.92it/s]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64:  50%|██████      | 9/18 [00:04<00:01,  4.81it/s]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64:  56%|██████     | 10/18 [00:04<00:01,  5.58it/s]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64:  67%|███████▎   | 12/18 [00:04<00:00,  6.85it/s]\u001b[A\n",
      "thread:1, f0ing, Hop-Length:64:  67%|███████▎   | 12/18 [00:04<00:00,  7.27it/s]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64:  72%|███████▉   | 13/18 [00:04<00:00,  6.94it/s]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64:  89%|█████████▊ | 16/18 [00:04<00:00,  9.14it/s]\u001b[A\n",
      "thread:0, f0ing, Hop-Length:64: 100%|███████████| 18/18 [00:05<00:00,  3.49it/s]\u001b[A\n",
      "\n",
      "thread:1, f0ing, Hop-Length:64: 100%|███████████| 18/18 [00:05<00:00,  3.45it/s]\u001b[A\n",
      "python3 Mangio-RVC-Fork/extract_feature_print.py device 1 0 0 \"Mangio-RVC-Fork/logs/v_voice\" v2\n",
      "['Mangio-RVC-Fork/extract_feature_print.py', 'device', '1', '0', '0', 'Mangio-RVC-Fork/logs/v_voice', 'v2']\n",
      "Mangio-RVC-Fork/logs/v_voice\n",
      "load model(s) from hubert_base.pt\n",
      "2023-10-14 15:05:45 | INFO | fairseq.tasks.hubert_pretraining | current directory is /home/vishnu/hackathon/content\n",
      "2023-10-14 15:05:45 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'metadata', 'fine_tuning': False, 'labels': ['km'], 'label_dir': 'label', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "2023-10-14 15:05:45 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\n",
      "/home/vishnu/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "move model to cuda\n",
      "all-feature-36\n",
      "now-0,all-36,0_1.wav,(149, 768)\n",
      "now-3,all-36,0_5.wav,(58, 768)\n",
      "now-6,all-36,1_2.wav,(149, 768)\n",
      "now-9,all-36,2_1.wav,(149, 768)\n",
      "now-12,all-36,2_6.wav,(44, 768)\n",
      "now-15,all-36,3_2.wav,(149, 768)\n",
      "now-18,all-36,3_6.wav,(149, 768)\n",
      "now-21,all-36,4_2.wav,(149, 768)\n",
      "now-24,all-36,5_2.wav,(163, 768)\n",
      "now-27,all-36,6_1.wav,(149, 768)\n",
      "now-30,all-36,7_1.wav,(149, 768)\n",
      "now-33,all-36,8_2.wav,(149, 768)\n",
      "all-feature-done\n"
     ]
    }
   ],
   "source": [
    "#@title Feature Extraction\n",
    "\n",
    "#pitch_extraction_algorithm = \"harvest\" #@param [\"harvest\", \"crepe\", \"mangio-crepe\"] {allow-input: false}\n",
    "#crepe_hop_length = 128 #@param {type:\"slider\", min:1, max:512, step:1}\n",
    "#pitch_guidance = True #@param {type:\"boolean\"}\n",
    "\n",
    "gpuList = gpus.split(\"-\")\n",
    "cmd = \"python3 Mangio-RVC-Fork/extract_f0_print.py \\\"%s/logs/%s\\\" %s %s %s\" % (now_dir, experiment_name, cpu_threads, pitch_extraction_algorithm, crepe_hop_length)\n",
    "print(cmd)\n",
    "!$cmd\n",
    "\n",
    "leng = len(gpus)\n",
    "\n",
    "cmd = \"python3 Mangio-RVC-Fork/extract_feature_print.py %s %s %s %s \\\"%s/logs/%s\\\" %s\" % (\"device\", leng, 0, 0, now_dir, experiment_name, model_architecture)\n",
    "print(cmd)\n",
    "!$cmd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content/Mangio-RVC-Fork\n"
     ]
    }
   ],
   "source": [
    "%cd Mangio-RVC-Fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: Mangio-RVC-Fork/logs/v_voice/ (stored 0%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/ (stored 0%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/4_4.wav.npy (deflated 84%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/0_3.wav.npy (deflated 85%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/3_5.wav.npy (deflated 85%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/8_1.wav.npy (deflated 82%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/1_1.wav.npy (deflated 86%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/3_2.wav.npy (deflated 85%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/8_4.wav.npy (deflated 83%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/2_1.wav.npy (deflated 86%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/7_0.wav.npy (deflated 85%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/6_1.wav.npy (deflated 87%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/2_4.wav.npy (deflated 84%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/3_6.wav.npy (deflated 87%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/6_0.wav.npy (deflated 87%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/3_4.wav.npy (deflated 87%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/6_3.wav.npy (deflated 82%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/0_2.wav.npy (deflated 84%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/2_0.wav.npy (deflated 88%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/5_3.wav.npy (deflated 87%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/8_5.wav.npy (deflated 88%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/5_2.wav.npy (deflated 87%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/3_1.wav.npy (deflated 86%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/5_1.wav.npy (deflated 86%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/7_1.wav.npy (deflated 87%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/0_1.wav.npy (deflated 85%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/0_5.wav.npy (deflated 83%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/4_1.wav.npy (deflated 84%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/1_2.wav.npy (deflated 85%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/0_6.wav.npy (deflated 82%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/1_4.wav.npy (deflated 85%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/7_3.wav.npy (deflated 86%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/2_6.wav.npy (deflated 83%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/3_0.wav.npy (deflated 85%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/3_8.wav.npy (deflated 82%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/8_2.wav.npy (deflated 84%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/4_2.wav.npy (deflated 84%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2a_f0/2_2.wav.npy (deflated 85%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/ (stored 0%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/4_4.wav.npy (deflated 23%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/0_3.wav.npy (deflated 26%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/3_5.wav.npy (deflated 12%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/8_1.wav.npy (deflated 47%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/1_1.wav.npy (deflated 35%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/3_2.wav.npy (deflated 14%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/8_4.wav.npy (deflated 22%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/2_1.wav.npy (deflated 26%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/7_0.wav.npy (deflated 27%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/6_1.wav.npy (deflated 21%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/2_4.wav.npy (deflated 14%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/3_6.wav.npy (deflated 24%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/6_0.wav.npy (deflated 27%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/3_4.wav.npy (deflated 29%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/6_3.wav.npy (deflated 38%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/0_2.wav.npy (deflated 22%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/2_0.wav.npy (deflated 45%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/5_3.wav.npy (deflated 33%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/8_5.wav.npy (deflated 42%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/5_2.wav.npy (deflated 27%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/3_1.wav.npy (deflated 24%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/5_1.wav.npy (deflated 25%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/7_1.wav.npy (deflated 19%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/0_1.wav.npy (deflated 25%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/0_5.wav.npy (deflated 47%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/4_1.wav.npy (deflated 18%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/1_2.wav.npy (deflated 24%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/0_6.wav.npy (deflated 47%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/1_4.wav.npy (deflated 21%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/7_3.wav.npy (deflated 28%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/2_6.wav.npy (deflated 36%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/3_0.wav.npy (deflated 24%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/3_8.wav.npy (deflated 24%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/8_2.wav.npy (deflated 15%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/4_2.wav.npy (deflated 23%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/2b-f0nsf/2_2.wav.npy (deflated 16%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/ (stored 0%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/2_4.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/0_1.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/6_3.npy (deflated 39%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/7_3.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/3_8.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/3_2.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/0_3.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/8_4.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/8_1.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/5_2.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/2_1.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/3_1.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/8_5.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/2_6.npy (deflated 39%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/2_0.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/5_3.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/4_2.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/3_0.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/3_5.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/0_5.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/6_1.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/0_6.npy (deflated 39%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/1_2.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/7_1.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/7_0.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/4_4.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/4_1.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/5_1.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/0_2.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/1_4.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/1_1.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/2_2.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/3_4.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/3_6.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/6_0.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/3_feature768/8_2.npy (deflated 40%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/extract_f0_feature.log (deflated 98%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/ (stored 0%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/4_4.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/2_4.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/1_4.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/3_2.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/0_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/8_2.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/6_3.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/0_5.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/7_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/3_8.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/3_6.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/5_3.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/4_2.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/5_2.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/7_3.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/3_5.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/3_0.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/8_5.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/2_0.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/4_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/6_0.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/3_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/8_4.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/7_0.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/6_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/0_3.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/2_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/2_6.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/8_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/1_2.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/0_2.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/2_2.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/3_4.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/0_6.wav (deflated 5%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/5_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/1_16k_wavs/1_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/preprocess.log (deflated 96%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/ (stored 0%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/4_4.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/2_4.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/1_4.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/3_2.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/0_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/8_2.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/6_3.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/0_5.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/7_1.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/3_8.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/3_6.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/5_3.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/4_2.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/5_2.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/7_3.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/3_5.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/3_0.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/8_5.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/2_0.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/4_1.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/6_0.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/3_1.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/8_4.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/7_0.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/6_1.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/0_3.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/2_1.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/2_6.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/8_1.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/1_2.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/0_2.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/2_2.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/3_4.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/0_6.wav (deflated 6%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/5_1.wav (deflated 7%)\n",
      "  adding: Mangio-RVC-Fork/logs/v_voice/0_gt_wavs/1_1.wav (deflated 7%)\n"
     ]
    }
   ],
   "source": [
    "#@title Save preprocessed dataset files to Google Drive\n",
    "#Compress dataset folder\n",
    "loc = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
    "!zip -r rvcLogs.zip \"{loc}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!cp content/Mangio-RVC-Fork/rvcLogs.zip \"rvcLogs.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon\n"
     ]
    }
   ],
   "source": [
    "%cd hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content/drive/MyDrive/rvcDisconnected/local_voice\n"
     ]
    }
   ],
   "source": [
    "%cd hackathon/content/drive/MyDrive/rvcDisconnected/local_voice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset files already loaded, skipping.\n"
     ]
    }
   ],
   "source": [
    "#@title Load preprocessed dataset files from Google Drive (for resuming)\n",
    "#@markdown If you already have preprocessed dataset files on Google Drive, you can load them here instead of re-running the preprocessing steps.\n",
    "import os\n",
    "\n",
    "BACK_UP_DATASET_PATH = \"drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
    "\n",
    "#Prevent people from loading the ZIP over existing files\n",
    "ok=True\n",
    "if(os.path.exists(\"Mangio-RVC-Fork/logs/\"+experiment_name+\"/2a_f0\")):\n",
    "  print(\"Dataset files already loaded, skipping.\")\n",
    "  ok=False\n",
    "\n",
    "if ok:\n",
    "  !unzip \"{BACK_UP_DATASET_PATH}/rvcLogs.zip\" -d /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying model files...\n",
      "cp: cannot stat 'drive/MyDrive/rvcDisconnected/v_voice/D_0.pth': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat 'drive/MyDrive/rvcDisconnected/v_voice/G_0.pth': No such file or directory\n",
      "cp: cannot stat 'drive/MyDrive/rvcDisconnected/v_voice/config.json': No such file or directory\n",
      "Copying Tensorboard TFEVENT files...\n",
      "All done. Welcome back!\n"
     ]
    }
   ],
   "source": [
    "#@title Import Model from Drive to Notebook (for resuming)\n",
    "import os\n",
    "\n",
    "DATASET_PATH_DRIVE = \"drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
    "DATASET_PATH_COLAB = \"Mangio-RVC-Fork/logs/\" + experiment_name\n",
    "#@markdown Input the model's Step Count here (the number located on your model's G and D files.) If you used `save_only_last_ckpt` during training, this number will be 2333333.\n",
    "STEPCOUNT = 000 #@param {type:\"integer\"}\n",
    "\n",
    "print(\"Copying model files...\")\n",
    "!cp \"{DATASET_PATH_DRIVE}/D_{STEPCOUNT}.pth\" \"{DATASET_PATH_COLAB}\"\n",
    "!cp \"{DATASET_PATH_DRIVE}/G_{STEPCOUNT}.pth\" \"{DATASET_PATH_COLAB}\"\n",
    "!cp \"{DATASET_PATH_DRIVE}/config.json\" \"{DATASET_PATH_COLAB}\"\n",
    "\n",
    "print(\"Copying Tensorboard TFEVENT files...\")\n",
    "for r, _, f in os.walk(DATASET_PATH_DRIVE):\n",
    "  for name in f:\n",
    "    if(name.startswith(\"events.out.tfevents\")):\n",
    "      !cp \"{DATASET_PATH_DRIVE}/{name}\" \"{DATASET_PATH_COLAB}\"\n",
    "\n",
    "print(\"All done. Welcome back!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content\n"
     ]
    }
   ],
   "source": [
    "%cd Mangio-RVC-Fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content/Mangio-RVC-Fork\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mangio-RVC-Fork\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "print(now_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content/Mangio-RVC-Fork\n"
     ]
    }
   ],
   "source": [
    "%cd Mangio-RVC-Fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content/Mangio-RVC-Fork\n"
     ]
    }
   ],
   "source": [
    "now_dir = \"/home/vishnu/hackathon/content/Mangio-RVC-Fork\"\n",
    "print(now_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 train_nsf_sim_cache_sid_load_pretrain.py -e \"v_voice\" -sr 48k -f0 1 -bs 20 -g 0 -te 5 -se 10 -pg pretrained_v2/f0G48k.pth -pd pretrained_v2/f0D48k.pth -l 1 -c 0 -sw 1 -v v2 -li 3\n",
      "yes\n",
      "Mute filelist written. Best of luck training!\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 26795), started 0:11:25 ago. (Use '!kill 26795' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4b91e4bdb2c4fa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4b91e4bdb2c4fa\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:v_voice:{'train': {'log_interval': 3, 'seed': 1234, 'epochs': 20000, 'learning_rate': 0.0001, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 20, 'fp16_run': True, 'lr_decay': 0.999875, 'segment_size': 17280, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'max_wav_value': 32768.0, 'sampling_rate': 48000, 'filter_length': 2048, 'hop_length': 480, 'win_length': 2048, 'n_mel_channels': 128, 'mel_fmin': 0.0, 'mel_fmax': None, 'training_files': './logs/v_voice/filelist.txt'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [12, 10, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [24, 20, 4, 4], 'use_spectral_norm': False, 'gin_channels': 256, 'spk_embed_dim': 109}, 'model_dir': './logs/v_voice', 'experiment_dir': './logs/v_voice', 'save_every_epoch': 10, 'name': 'v_voice', 'total_epoch': 5, 'pretrainG': 'pretrained_v2/f0G48k.pth', 'pretrainD': 'pretrained_v2/f0D48k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '48k', 'if_f0': 1, 'if_latest': 1, 'save_every_weights': '1', 'if_cache_data_in_gpu': 0}\n",
      "/home/vishnu/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "gin_channels: 256 self.spk_embed_dim: 109\n",
      "INFO:v_voice:loaded pretrained pretrained_v2/f0G48k.pth\n",
      "<All keys matched successfully>\n",
      "INFO:v_voice:loaded pretrained pretrained_v2/f0D48k.pth\n",
      "<All keys matched successfully>\n",
      "/home/vishnu/.local/lib/python3.10/site-packages/torch/functional.py:650: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:863.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vishnu/hackathon/content/Mangio-RVC-Fork/train_nsf_sim_cache_sid_load_pretrain.py\", line 270, in run\n",
      "    train_and_evaluate(\n",
      "  File \"/home/vishnu/hackathon/content/Mangio-RVC-Fork/train_nsf_sim_cache_sid_load_pretrain.py\", line 477, in train_and_evaluate\n",
      "    scaler.scale(loss_gen_all).backward()\n",
      "  File \"/home/vishnu/.local/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/vishnu/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from random import shuffle\n",
    "\n",
    "# I will not be adding an autosave feature. Do not ask.\n",
    "\n",
    "#@title Training\n",
    "save_frequency = 10 #@param {type:\"integer\"}\n",
    "total_epochs = 5 #@param {type:\"integer\"}\n",
    "batch_size = 20 #@param {type:\"integer\"}\n",
    "save_only_latest_ckpt = True #@param {type:\"boolean\"}\n",
    "cache_all_training_sets = False #@param {type:\"boolean\"}\n",
    "save_small_final_model = True #@param {type:\"boolean\"}\n",
    "#@markdown The automatically calculated log interval is known to be very inaccurate and can cause delays between an epoch finishing and Tensorboard writes. If you would like, you can manually define a log interval here.\n",
    "use_manual_stepToEpoch = False #@param {type:\"boolean\"}\n",
    "manual_stepToEpoch = 000 #@param {type:\"integer\"}\n",
    "\n",
    "assert save_frequency!=None, \"You need to input something for save_frequency, silly.\"\n",
    "assert save_frequency>0, \"Save frequency must be more than 0.\"\n",
    "if(save_frequency>50):print(\"...A save frequency of %s? A bit high, but... alright then.\"%save_frequency)\n",
    "assert total_epochs!=None, \"You need to input something for total_epochs, silly.\"\n",
    "assert total_epochs>0, \"Total epochs must be more than 0.\"\n",
    "if(total_epochs>10000):print(\"...A total epoch count of of %s? This is going to overtrain, but... alright then.\"%total_epochs)\n",
    "assert batch_size!=None, \"You need to input something for batch_size, silly.\"\n",
    "assert batch_size>0, \"Batch size must be more than 0.\"\n",
    "assert batch_size<=40, \"Batch size must be less than 40. (I'd reccomend a value between 6 and 12 for Colab.)\"\n",
    "\n",
    "pretrained_base = \"pretrained/\" if model_architecture == \"v1\" else \"pretrained_v2/\"\n",
    "exp_dir = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
    "\n",
    "pretrainedD = \"%sf0D%s.pth\" % (pretrained_base, target_sample_rate)\n",
    "pretrainedG = \"%sf0G%s.pth\" % (pretrained_base, target_sample_rate)\n",
    "\n",
    "#Log interval\n",
    "log_interval = 1\n",
    "liFolderPath = os.path.join(exp_dir, \"1_16k_wavs\")\n",
    "if(os.path.exists(liFolderPath) and os.path.isdir(liFolderPath)):\n",
    "  wav_files = [f for f in os.listdir(liFolderPath) if f.endswith(\".wav\")]\n",
    "  if wav_files:\n",
    "    sample_size = len(wav_files)\n",
    "    log_interval = math.ceil(sample_size / batch_size)\n",
    "    if log_interval > 1:\n",
    "      log_interval += 1\n",
    "\n",
    "if log_interval > 250 and not use_manual_stepToEpoch:\n",
    "  print(\"That's a big dataset you got there. Log interval normalized to 200 steps from %s steps.\" % log_interval)\n",
    "  log_interval = 200\n",
    "\n",
    "if use_manual_stepToEpoch:\n",
    "  log_interval = manual_stepToEpoch\n",
    "\n",
    "#Create Python command\n",
    "cmd = \"python3 train_nsf_sim_cache_sid_load_pretrain.py -e \\\"%s\\\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s -li %s\" % (\n",
    "    experiment_name,\n",
    "    target_sample_rate,\n",
    "    1,\n",
    "    batch_size,\n",
    "    0,\n",
    "    total_epochs,\n",
    "    save_frequency,\n",
    "    \"-pg %s\" % pretrainedG if pretrainedG != \"\" else \"\\b\",\n",
    "    \"-pd %s\" % pretrainedD if pretrainedD != \"\" else \"\\b\",\n",
    "    1 if save_only_latest_ckpt else 0,\n",
    "    1 if cache_all_training_sets else 0,\n",
    "    1 if save_small_final_model else 0,\n",
    "    model_architecture,\n",
    "    log_interval,\n",
    ")\n",
    "print(cmd)\n",
    "print('yes')\n",
    "\n",
    "#Create mute filelist\n",
    "exp_dir = \"logs/%s\" % ( experiment_name)\n",
    "gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
    "feature_dir = (\n",
    "  \"%s/3_feature256\" % (exp_dir)\n",
    "  if model_architecture == \"v1\"\n",
    "  else \"%s/3_feature768\" % (exp_dir)\n",
    ")\n",
    "f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
    "f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
    "names = (\n",
    "  set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
    "  & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
    "  & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
    "  & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
    ")\n",
    "opt = []\n",
    "for name in names:\n",
    "  opt.append(\n",
    "    \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
    "    % (\n",
    "      gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
    "      name,\n",
    "      feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
    "      name,\n",
    "      f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
    "      name,\n",
    "      f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
    "      name,\n",
    "      speaker_id,\n",
    "    )\n",
    "  )\n",
    "fea_dim = 256 if model_architecture == \"v1\" else 768\n",
    "for _ in range(2):\n",
    "  opt.append(\n",
    "      \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
    "      % (now_dir, target_sample_rate, now_dir, fea_dim, now_dir, now_dir, speaker_id)\n",
    "  )\n",
    "shuffle(opt)\n",
    "with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
    "  f.write(\"\\n\".join(opt))\n",
    "print(\"Mute filelist written. Best of luck training!\")\n",
    "\n",
    "\n",
    "#%cd content/Mangio-RVC-Fork\n",
    "#%cd Mangio-RVC-Fork\n",
    "%load_ext tensorboard\n",
    "#%tensorboard --logdir content/Mangio-RVC-Fork/logs\n",
    "%tensorboard --logdir logs\n",
    "\n",
    "#os.chdir('content/Mangio-RVC-Fork')\n",
    "!$cmd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishnu/hackathon/content/Mangio-RVC-Fork\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "from lib1.infer_pack import commons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, os\n",
    "sys.path.append('/home/vishnu/hackathon/content/Mangio-RVC-Fork')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
